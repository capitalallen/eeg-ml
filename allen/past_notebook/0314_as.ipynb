{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mat_np(gender=None):\n",
    "    f_file = \"../raw_data/Emotrans1_girl_data_preprocessed_42.mat\"\n",
    "    m_file = \"../raw_data/Emotrans1_Boy_data_preprocessed_42.mat\"\n",
    "    # m_file = \"../raw_data/Emotrans1_Boy_data_preprocessed_33.mat\"\n",
    "    # f_file = \"../raw_data/Emotrans1_girl_data_preprocessed_33.mat\"\n",
    "    if gender == \"f\":\n",
    "        data_dict_female = mat73.loadmat(f_file, use_attrdict=True)\n",
    "        return np.array(data_dict_female[\"All_Feature\"])\n",
    "    elif gender == 'm':\n",
    "        data_dict_female = mat73.loadmat(m_file, use_attrdict=True)\n",
    "        return np.array(data_dict_female[\"All_Feature\"])  \n",
    "    else: \n",
    "        raise Exception(\"gender not defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-fe3f77dfe444>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(data_dict_female[\"All_Feature\"])\n",
      "<ipython-input-2-fe3f77dfe444>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(data_dict_female[\"All_Feature\"])\n"
     ]
    }
   ],
   "source": [
    "m = convert_mat_np(\"m\")\n",
    "f = convert_mat_np(\"f\")\n",
    "combined = np.concatenate((m,f),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 4, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: 0 --> average 3+4 and 1+2; 1--> use only 3 and 2  \n",
    "def get_pos_or_neg(data,position,type=0):\n",
    "    arr = []\n",
    "    index = 0\n",
    "    for i in range(data.shape[0]):\n",
    "#         print(data[i].shape)\n",
    "        if type == 0:\n",
    "            diff = (data[i][position[0][0]][position[0][1]]+data[i][position[1][0]][position[1][1]])/2 - (data[i][position[3][0]][position[3][1]]+data[i][position[2][0]][position[2][1]])/2\n",
    "        elif type == 1:\n",
    "             diff = (data[i][position[1][0]][position[1][1]] - data[i][position[2][0]][position[2][1]])/2\n",
    "        arr.append(diff)\n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select frequenceis and (0-4s -> 0 or 0.5-4.5s -> 1)\n",
    "# output: x \n",
    "def choose_freq(data=None,freq = None, sec=None):\n",
    "    if freq:\n",
    "        data = np.delete(data,freq,axis=3)\n",
    "    if sec == 0:\n",
    "        for i in range(data.shape[0]):\n",
    "            data[i] = np.delete(data[i], 1, axis=3)\n",
    "        return data\n",
    "    elif sec == 1:\n",
    "        for i in range(data.shape[0]):\n",
    "            data[i] = np.delete(data[i], 0, axis=3) \n",
    "        return data\n",
    "    else:\n",
    "        print('sec not specified')\n",
    "        return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to 128*8*2 = 2048\n",
    "# return x \n",
    "def squeeze_feature_size(data):\n",
    "    new_data = []\n",
    "    for d in range(data.shape[0]):\n",
    "#         for i in range(df[d].shape[0]):\n",
    "        size = data[d].shape\n",
    "        new_data.append(data[d].reshape(size[0], size[1]*size[2]*size[3]))  \n",
    "    return np.array(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels for x \n",
    "# input: data and label_type (0:zeros, 1: ones )\n",
    "def generate_labels(df,type=None):\n",
    "    arr = []\n",
    "    label = []\n",
    "    label_type = -1\n",
    "    if type == 0:\n",
    "        label_type = 0\n",
    "    elif type == 1:\n",
    "        label_type = 1\n",
    "    else:\n",
    "        print(\"Wrong type - get_pos_or_neg()\")\n",
    "        return \n",
    "    for d in range(df.shape[0]):\n",
    "#         for i in range(df[d].shape[0]):\n",
    "        size = df[d].shape\n",
    "#         print(size)\n",
    "        if label_type == 1:\n",
    "            label.append(np.ones((size[0],1)))\n",
    "        else:\n",
    "            label.append(np.zeros((size[0],1)))\n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine neg and postive for boys and girls separately\n",
    "def combine_net_neg(netX,netY,negX,negY):\n",
    "    new_x, new_y = [],[]\n",
    "    for i in range(netX.shape[0]):\n",
    "        new_x.append(np.concatenate((netX[i],negX[i]),axis=0))\n",
    "        new_y.append(np.concatenate((netY[i],negY[i]),axis=0))\n",
    "    return np.array(new_x),np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get x and y training set for leave one out \n",
    "def get_x_y_train(x,y):\n",
    "    new_x = x[0]\n",
    "    new_y = y[0]\n",
    "    for i in range(1,len(x)):\n",
    "        new_x=np.append(new_x,x[i],axis=0)\n",
    "        new_y=np.append(new_y,y[i],axis=0)\n",
    "    return new_x,new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "model = RandomForestClassifier(n_estimators=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-b80872df8784>:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(arr)\n"
     ]
    }
   ],
   "source": [
    "pos = [[0,3],[0,2],[0,1],[0,0]]\n",
    "neg = [[1,3],[1,2],[1,1],[1,0]]\n",
    "pos_df_m = get_pos_or_neg(m,pos,1)\n",
    "neg_df_m = get_pos_or_neg(m,neg,1)\n",
    "pos_df_f = get_pos_or_neg(f,pos,1)\n",
    "neg_df_f = get_pos_or_neg(f,neg,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_features(df):\n",
    "    new_df=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        temp = df[i][:,:,1:3,:]\n",
    "        temp2 = df[i][:,:,4:6,:]\n",
    "        new_df.append(np.concatenate((temp,temp2),axis=2))\n",
    "    return np.array(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(x_train,x_test,y_train,y_test,model):\n",
    "    model.fit(x_train,y_train.ravel())\n",
    "    y_pred = model.predict(x_test)\n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get x train and test set for witin CV \n",
    "def get_x_train_test(data,index):\n",
    "    x_test = data[index]\n",
    "    x_train = np.delete(data,index,axis=0)\n",
    "    return x_train,x_test.reshape(1,-1)\n",
    "\n",
    "# get y train and test set for witin CV \n",
    "def get_y_train_test(data,index):\n",
    "    y_test = data[index]\n",
    "    y_train = np.delete(data,index,axis=0)\n",
    "    return y_train.astype(int).ravel(),y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-be03b35ddd19>:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(new_df)\n"
     ]
    }
   ],
   "source": [
    "pos_df_m = get_new_features(pos_df_m)\n",
    "neg_df_m = get_new_features(neg_df_m)\n",
    "pos_df_f = get_new_features(pos_df_f)\n",
    "neg_df_f = get_new_features(neg_df_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-f7e19f44a14e>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(new_data)\n"
     ]
    }
   ],
   "source": [
    "pos_sequeezed_m = squeeze_feature_size(pos_df_m)\n",
    "neg_sequeezed_m = squeeze_feature_size(neg_df_m)\n",
    "pos_sequeezed_f = squeeze_feature_size(pos_df_f)\n",
    "neg_sequeezed_f = squeeze_feature_size(neg_df_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-6902f150008f>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(label)\n"
     ]
    }
   ],
   "source": [
    "pos_labels_m = generate_labels(pos_sequeezed_m,1)\n",
    "neg_labels_m = generate_labels(neg_sequeezed_m,0)\n",
    "pos_labels_f = generate_labels(pos_sequeezed_f,1)\n",
    "neg_labels_f = generate_labels(neg_sequeezed_f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-ef61bbcee622>:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(new_x),np.array(new_y)\n"
     ]
    }
   ],
   "source": [
    "boy_x,boy_y = combine_net_neg(pos_sequeezed_m,pos_labels_m,neg_sequeezed_m,neg_labels_m)\n",
    "girl_x,girl_y = combine_net_neg(pos_sequeezed_f,pos_labels_f,neg_sequeezed_f,neg_labels_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine boys and girls \n",
    "x = np.concatenate((boy_x,girl_x),axis=0)\n",
    "y = np.concatenate((boy_y,girl_y),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leave one out # person: 0\n",
      "leave one out # person: 1\n",
      "leave one out # person: 2\n",
      "leave one out # person: 3\n",
      "leave one out # person: 4\n",
      "leave one out # person: 5\n",
      "leave one out # person: 6\n",
      "leave one out # person: 7\n",
      "leave one out # person: 8\n",
      "leave one out # person: 9\n",
      "leave one out # person: 10\n",
      "leave one out # person: 11\n",
      "leave one out # person: 12\n",
      "leave one out # person: 13\n",
      "leave one out # person: 14\n",
      "leave one out # person: 15\n",
      "leave one out # person: 16\n",
      "leave one out # person: 17\n",
      "leave one out # person: 18\n",
      "leave one out # person: 19\n",
      "leave one out # person: 20\n",
      "leave one out # person: 21\n",
      "leave one out # person: 22\n",
      "leave one out # person: 23\n",
      "leave one out # person: 24\n",
      "leave one out # person: 25\n",
      "leave one out # person: 26\n",
      "leave one out # person: 27\n",
      "leave one out # person: 28\n",
      "leave one out # person: 29\n",
      "leave one out # person: 30\n",
      "leave one out # person: 31\n",
      "leave one out # person: 32\n",
      "leave one out # person: 33\n",
      "leave one out # person: 34\n",
      "leave one out # person: 35\n",
      "leave one out # person: 36\n",
      "leave one out # person: 37\n",
      "leave one out # person: 38\n",
      "leave one out # person: 39\n",
      "leave one out # person: 40\n",
      "leave one out # person: 41\n",
      "[0.8055555555555556, 0.6388888888888888, 0.6944444444444444, 0.5277777777777778, 0.75, 0.75, 0.8611111111111112, 0.75, 0.6388888888888888, 0.6944444444444444, 0.5666666666666667, 0.5333333333333333, 0.6666666666666666, 0.7, 0.6944444444444444, 0.6666666666666666, 0.6944444444444444, 0.6111111111111112, 0.5833333333333334, 0.5277777777777778, 0.6388888888888888, 0.6388888888888888, 0.6666666666666666, 0.7222222222222222, 0.6666666666666666, 0.6666666666666666, 0.7222222222222222, 0.6388888888888888, 0.6388888888888888, 0.5833333333333334, 0.7777777777777778, 0.8611111111111112, 0.75, 0.6388888888888888, 0.7777777777777778, 0.6944444444444444, 0.5833333333333334, 0.6388888888888888, 0.8333333333333334, 0.7, 0.7333333333333333, 0.6]\n"
     ]
    }
   ],
   "source": [
    "all_accuracy=[]\n",
    "for d in range(x.shape[0]):\n",
    "    print(\"leave one out # person:\",d)\n",
    "    if d == 0:\n",
    "        x_train,y_train = get_x_y_train(x[d+1:],y[d+1:])\n",
    "        x_test,y_test =x[d],y[d]\n",
    "    elif d == x.shape[0]-1:\n",
    "        x_train,y_train = get_x_y_train(x[:d],y[:d])\n",
    "        x_test,y_test = x[d],y[d]\n",
    "    else:\n",
    "        x_train,y_train = get_x_y_train(np.append(x[:d],x[d+1:],axis=0),np.append(y[:d],y[d+1:],axis=0))\n",
    "        x_test,y_test = x[d],y[d]\n",
    "    # print(x_train.shape,x_test.shape)\n",
    "    # print(y_train.shape,y_test.shape)\n",
    "    # return\n",
    "    y_test,y_pred=model_train(x_train,x_test,y_train,y_test,model)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    all_accuracy.append(accuracy)\n",
    "print(all_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    all_accuracy.append(-1)\n",
    "df = pd.read_csv('feb_27.csv')\n",
    "print(len(all_accuracy))\n",
    "df[\"between_Feature_selected\"] = all_accuracy[:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1b246beb455a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.../table.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv('.../table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within # person: 0\n",
      "within # person: 1\n",
      "within # person: 2\n",
      "within # person: 3\n",
      "within # person: 4\n",
      "within # person: 5\n",
      "within # person: 6\n",
      "within # person: 7\n",
      "within # person: 8\n",
      "within # person: 9\n",
      "within # person: 10\n",
      "within # person: 11\n",
      "within # person: 12\n",
      "within # person: 13\n",
      "within # person: 14\n",
      "within # person: 15\n",
      "within # person: 16\n",
      "within # person: 17\n",
      "within # person: 18\n",
      "within # person: 19\n",
      "within # person: 20\n",
      "within # person: 21\n",
      "within # person: 22\n",
      "within # person: 23\n",
      "within # person: 24\n",
      "within # person: 25\n",
      "within # person: 26\n",
      "within # person: 27\n",
      "within # person: 28\n",
      "within # person: 29\n",
      "within # person: 30\n",
      "within # person: 31\n",
      "within # person: 32\n",
      "within # person: 33\n",
      "within # person: 34\n",
      "within # person: 35\n",
      "within # person: 36\n",
      "within # person: 37\n",
      "within # person: 38\n",
      "within # person: 39\n",
      "within # person: 40\n",
      "within # person: 41\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Within \n",
    "\"\"\"\n",
    "all_accuracy = []\n",
    "# train a model \n",
    "# return y_test, y_pred \n",
    "avg_accuracy = []\n",
    "for d in range(x.shape[0]):\n",
    "    # training set and test set\n",
    "    accuracy =[]\n",
    "    print(\"within # person:\",d)\n",
    "    for i in range(x[d].shape[0]):\n",
    "        x_train,x_test = get_x_train_test(x[d],i)\n",
    "        y_train,y_test = get_y_train_test(y[d],i)\n",
    "        y_test,y_pred = model_train(x_train,x_test,y_train,y_test,model)\n",
    "        accuracy.append(accuracy_score(y_test,y_pred))\n",
    "    avg_accuracy.append(sum(accuracy)/len(accuracy))\n",
    "    all_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7222222222222222, 0.6666666666666666, 0.6666666666666666, 0.5555555555555556, 0.6111111111111112, 0.75, 0.8055555555555556, 0.6111111111111112, 0.6111111111111112, 0.5, 0.7333333333333333, 0.9, 0.6666666666666666, 0.4666666666666667, 0.5833333333333334, 0.75, 0.5555555555555556, 0.5277777777777778, 0.7916666666666666, 0.6388888888888888, 0.6944444444444444, 0.5555555555555556, 0.5, 0.6388888888888888, 0.7222222222222222, 0.6944444444444444, 0.6944444444444444, 0.5277777777777778, 0.5555555555555556, 0.7222222222222222, 0.9444444444444444, 0.8055555555555556, 0.75, 0.6666666666666666, 0.6944444444444444, 0.7777777777777778, 0.6666666666666666, 0.6111111111111112, 0.8055555555555556, 0.6666666666666666, 0.4666666666666667, 0.4666666666666667]\n"
     ]
    }
   ],
   "source": [
    "print(avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(avg_accuracy)):\n",
    "    avg_accuracy[i] = round(avg_accuracy[i],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../table.csv')\n",
    "for i in range(10):\n",
    "    avg_accuracy.append(-1)\n",
    "df[\"within_Feature_Less_RF\"] = avg_accuracy[:52]\n",
    "df.to_csv('../table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(22):\n",
    "    avg_accuracy.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    avg_accuracy.append(-1)\n",
    "df[\"within_Feature_asymmtry\"] = avg_accuracy[:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    avg_accuracy.append(-1)\n",
    "df[\"within_Feature_asymmtry\"] = avg_accuracy[:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6708571428571426"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accs[:42])/len(accs[:42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.722,\n",
       " 0.611,\n",
       " 0.722,\n",
       " 0.611,\n",
       " 0.722,\n",
       " 0.722,\n",
       " 0.861,\n",
       " 0.639,\n",
       " 0.667,\n",
       " 0.639,\n",
       " 0.8,\n",
       " 0.5,\n",
       " 0.583,\n",
       " 0.667,\n",
       " 0.611,\n",
       " 0.639,\n",
       " 0.694,\n",
       " 0.5,\n",
       " 0.583,\n",
       " 0.583,\n",
       " 0.722,\n",
       " 0.806,\n",
       " 0.639,\n",
       " 0.694,\n",
       " 0.667,\n",
       " 0.611,\n",
       " 0.528,\n",
       " 0.778,\n",
       " 0.778,\n",
       " 0.639,\n",
       " 0.778,\n",
       " 0.694,\n",
       " 0.722,\n",
       " 0.5,\n",
       " 0.778,\n",
       " 0.833,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.533,\n",
       " 0.639,\n",
       " 0.667,\n",
       " 0.694,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
