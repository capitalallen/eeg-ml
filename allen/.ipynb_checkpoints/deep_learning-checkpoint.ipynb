{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data import Data_prepare\n",
    "import numpy as np \n",
    "import os \n",
    "# import prep_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data preprocessing \n",
    "1. covert mat data to numpy array \n",
    "2. combine male and female data to one array \n",
    "3. if needed, remove certain rows \n",
    "4. get postive and negative of Xs \n",
    "    - order difference or net vs neg \n",
    "5. reshape each X: 128*8*2 = 2048 \n",
    "    - input: data \n",
    "6. generate labels for x \n",
    "    - input: data and label_type (0:zeros, 1: ones )\n",
    "7. combine net and neg \n",
    "    - input: netX,netY,negX,negY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = Data_prepare() \n",
    "pos = [[0,3],[0,2],[0,1],[0,0]]\n",
    "neg = [[1,3],[1,2],[1,1],[1,0]]\n",
    "# netural vs postive \n",
    "# pos = [[0,0],[0,1],[1,2],[1,3],[2,0],[2,1],[2,2],[2,3]]\n",
    "# neg = [[0,2],[0,3],[1,0],[1,1],[3,0],[3,1],[3,2],[3,3]] \n",
    "m_file = \"./raw_data/Emotrans1_Boy_data_preprocessed_42.mat\" \n",
    "f_file = \"./raw_data/Emotrans1_girl_data_preprocessed_42.mat\"\n",
    "index = [11,18,36]\n",
    "df = dp.combine_male_female(m_file,f_file)\n",
    "df = dp.remove_person(df,index)\n",
    "pos_df = dp.get_pos_or_neg(df,pos)\n",
    "neg_df = dp.get_pos_or_neg(df,neg)\n",
    "pos_sequeezed = dp.squeeze_feature_size(pos_df)\n",
    "neg_sequeezed = dp.squeeze_feature_size(neg_df)\n",
    "pos_labels = dp.generate_labels(pos_sequeezed,1)\n",
    "neg_labels = dp.generate_labels(neg_sequeezed,0)\n",
    "x,y = dp.combine_net_neg(pos_sequeezed,pos_labels,neg_sequeezed,neg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (40,) -> 40*36*2048\n",
    "def flatten(data):\n",
    "    res = data[0]\n",
    "    for i in range(1,data.shape[0]):\n",
    "        res = np.append(res,data[i],axis=0)\n",
    "    return res \n",
    "new_x = flatten(x)\n",
    "new_y = flatten(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1374, 2048) (1374, 1)\n"
     ]
    }
   ],
   "source": [
    "print(new_x.shape,new_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize x with standardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(new_x)\n",
    "new_x = scaler.transform(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1374, 2048) (1374, 1)\n"
     ]
    }
   ],
   "source": [
    "print(new_x.shape,new_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_x, new_y, test_size = 0.1, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1236, 2048) (1236, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reshape x_train and x_test to 3D for LSTM \n",
    "x_train = np.reshape(x_train, (x_train.shape[0],1,new_x.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],1,new_x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "# y_test = np.asarray(y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1236, 1, 2048) (138, 1, 2048)\n",
      "(1236, 1) (138, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 512)            5244928   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 256)            787456    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 128)            197120    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 16)                9280      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 6,370,402\n",
      "Trainable params: 6,370,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(1,2048),activation=\"relu\",return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256,activation=\"relu\",return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128,activation=\"relu\",return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128,activation=\"relu\",return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(16,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(50))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "from keras.optimizers import SGD\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 2/39 [>.............................] - ETA: 6s - loss: 0.6932 - accuracy: 0.4531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0220s vs `on_train_batch_end` time: 0.3292s). Check your callbacks.\n",
      "39/39 [==============================] - 2s 58ms/step - loss: 0.7017 - accuracy: 0.5858 - val_loss: 0.5693 - val_accuracy: 0.7319\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.6533 - accuracy: 0.6788 - val_loss: 0.5839 - val_accuracy: 0.7391\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.6793 - accuracy: 0.7087 - val_loss: 0.4724 - val_accuracy: 0.7536\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.5993 - accuracy: 0.7193 - val_loss: 0.4537 - val_accuracy: 0.7754\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.6023 - accuracy: 0.7751 - val_loss: 0.4327 - val_accuracy: 0.7899\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.5284 - accuracy: 0.7896 - val_loss: 0.5186 - val_accuracy: 0.7899\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4642 - accuracy: 0.8091 - val_loss: 0.5392 - val_accuracy: 0.7464\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4270 - accuracy: 0.8099 - val_loss: 0.6787 - val_accuracy: 0.7536\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4132 - accuracy: 0.8463 - val_loss: 0.7560 - val_accuracy: 0.7681\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.4177 - accuracy: 0.8455 - val_loss: 0.9283 - val_accuracy: 0.7101\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.3898 - accuracy: 0.8463 - val_loss: 1.0960 - val_accuracy: 0.7681\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.3356 - accuracy: 0.8600 - val_loss: 1.1716 - val_accuracy: 0.7319\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.3164 - accuracy: 0.8827 - val_loss: 0.9406 - val_accuracy: 0.7319\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.3005 - accuracy: 0.8867 - val_loss: 1.1122 - val_accuracy: 0.7536\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.2967 - accuracy: 0.8859 - val_loss: 1.1216 - val_accuracy: 0.7681\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.2355 - accuracy: 0.8989 - val_loss: 1.6744 - val_accuracy: 0.7609\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1983 - accuracy: 0.9231 - val_loss: 2.1673 - val_accuracy: 0.7464\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1847 - accuracy: 0.9385 - val_loss: 2.3088 - val_accuracy: 0.6884\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.2172 - accuracy: 0.9320 - val_loss: 1.4838 - val_accuracy: 0.7899\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.2980 - accuracy: 0.9126 - val_loss: 1.3929 - val_accuracy: 0.7899\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.2518 - accuracy: 0.9134 - val_loss: 1.3899 - val_accuracy: 0.7754\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.2403 - accuracy: 0.9159 - val_loss: 1.1675 - val_accuracy: 0.7609\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.2444 - accuracy: 0.9450 - val_loss: 0.9217 - val_accuracy: 0.7609\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1733 - accuracy: 0.9466 - val_loss: 1.1166 - val_accuracy: 0.7681\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.2251 - accuracy: 0.9401 - val_loss: 0.8013 - val_accuracy: 0.7681\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1936 - accuracy: 0.9434 - val_loss: 1.6188 - val_accuracy: 0.7536\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1362 - accuracy: 0.9531 - val_loss: 2.1402 - val_accuracy: 0.7609\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.2270 - accuracy: 0.9417 - val_loss: 1.4814 - val_accuracy: 0.7681\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1410 - accuracy: 0.9579 - val_loss: 1.5641 - val_accuracy: 0.7536\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0987 - accuracy: 0.9604 - val_loss: 2.3196 - val_accuracy: 0.7391\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1521 - accuracy: 0.9612 - val_loss: 1.2785 - val_accuracy: 0.7754\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0942 - accuracy: 0.9652 - val_loss: 2.2055 - val_accuracy: 0.7536\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1083 - accuracy: 0.9668 - val_loss: 2.1824 - val_accuracy: 0.7319\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0998 - accuracy: 0.9757 - val_loss: 2.1599 - val_accuracy: 0.7536\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0964 - accuracy: 0.9814 - val_loss: 2.2672 - val_accuracy: 0.7681\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1003 - accuracy: 0.9693 - val_loss: 1.5470 - val_accuracy: 0.7754\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1326 - accuracy: 0.9798 - val_loss: 1.7333 - val_accuracy: 0.7971\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1176 - accuracy: 0.9725 - val_loss: 1.4470 - val_accuracy: 0.8116\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1391 - accuracy: 0.9652 - val_loss: 1.3605 - val_accuracy: 0.7681\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1263 - accuracy: 0.9709 - val_loss: 1.3940 - val_accuracy: 0.7754\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1495 - accuracy: 0.9725 - val_loss: 1.9933 - val_accuracy: 0.7391\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0964 - accuracy: 0.9741 - val_loss: 1.4231 - val_accuracy: 0.7754\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0611 - accuracy: 0.9814 - val_loss: 2.5532 - val_accuracy: 0.7464\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1017 - accuracy: 0.9773 - val_loss: 1.7107 - val_accuracy: 0.7681\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.0856 - accuracy: 0.9822 - val_loss: 1.6821 - val_accuracy: 0.7536\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0662 - accuracy: 0.9846 - val_loss: 2.0904 - val_accuracy: 0.7536\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0520 - accuracy: 0.9838 - val_loss: 2.0974 - val_accuracy: 0.7754\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0563 - accuracy: 0.9838 - val_loss: 2.4703 - val_accuracy: 0.7536\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0239 - accuracy: 0.9935 - val_loss: 3.6397 - val_accuracy: 0.7536\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.0851 - accuracy: 0.9854 - val_loss: 1.9705 - val_accuracy: 0.7754\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9705 - accuracy: 0.7754\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "history = model.fit(x_train, y_train, epochs = 50, validation_data= (x_test, y_test),callbacks=[tensorboard_callback])\n",
    "score, acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### leave one out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reshape \n",
    "x_train = np.reshape(x_train, (x_train.shape[0],new_x.shape[1],1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],new_x.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1236, 2048, 1) (138, 2048, 1)\n",
      "(1236, 1) (138, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2039, 16)          176       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2037, 16)          784       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1018, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16288)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               1628900   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 1,630,163\n",
      "Trainable params: 1,630,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(16, 10, activation='relu',input_shape=(2048,1)))\n",
    "model.add(layers.Conv1D(16, 3, activation='relu'))\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(100,activation=\"relu\"))\n",
    "model.add(layers.Dense(3,activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "# input_shape = (trial_length, nchan, 1)\n",
    "# l1 = 0\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(40, (30, 1), activation=\"relu\", kernel_regularizer=regularizers.l1(l1), padding=\"same\", input_shape=(2048,1)))\n",
    "# model.add(Conv2D(40, (1, nchan), activation=\"relu\", kernel_regularizer=regularizers.l1(l1), padding=\"valid\"))\n",
    "# model.add(AveragePooling2D((30, 1), strides=(15, 1)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(80, activation=\"relu\"))\n",
    "# model.add(Dense(2, activation=\"softmax\"))\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.2049 - accuracy: 0.9231 - val_loss: 0.6175 - val_accuracy: 0.7319\n",
      "Epoch 2/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.1816 - accuracy: 0.9304 - val_loss: 0.6375 - val_accuracy: 0.7319\n",
      "Epoch 3/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.1442 - accuracy: 0.9628 - val_loss: 0.7088 - val_accuracy: 0.7536\n",
      "Epoch 4/30\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.1179 - accuracy: 0.9636 - val_loss: 0.7885 - val_accuracy: 0.7464\n",
      "Epoch 5/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.1055 - accuracy: 0.9741 - val_loss: 0.9229 - val_accuracy: 0.7536\n",
      "Epoch 6/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.1149 - accuracy: 0.9668 - val_loss: 0.8137 - val_accuracy: 0.7681\n",
      "Epoch 7/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.1165 - accuracy: 0.9604 - val_loss: 0.8468 - val_accuracy: 0.7319\n",
      "Epoch 8/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0814 - accuracy: 0.9814 - val_loss: 0.8861 - val_accuracy: 0.7464\n",
      "Epoch 9/30\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.99 - 1s 22ms/step - loss: 0.0478 - accuracy: 0.9919 - val_loss: 1.0778 - val_accuracy: 0.7464\n",
      "Epoch 10/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0352 - accuracy: 0.9951 - val_loss: 1.0543 - val_accuracy: 0.7464\n",
      "Epoch 11/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0247 - accuracy: 0.9992 - val_loss: 1.0694 - val_accuracy: 0.7246\n",
      "Epoch 12/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.7681\n",
      "Epoch 13/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.1969 - val_accuracy: 0.7101\n",
      "Epoch 14/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.3192 - val_accuracy: 0.7174\n",
      "Epoch 15/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0179 - accuracy: 0.9984 - val_loss: 1.1055 - val_accuracy: 0.7246\n",
      "Epoch 16/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0939 - accuracy: 0.9782 - val_loss: 0.9707 - val_accuracy: 0.7754\n",
      "Epoch 17/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0957 - accuracy: 0.9830 - val_loss: 1.3311 - val_accuracy: 0.7464\n",
      "Epoch 18/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.1747 - accuracy: 0.9571 - val_loss: 1.7244 - val_accuracy: 0.7174\n",
      "Epoch 19/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.1559 - accuracy: 0.9506 - val_loss: 1.3700 - val_accuracy: 0.6884\n",
      "Epoch 20/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.1110 - accuracy: 0.9668 - val_loss: 1.1294 - val_accuracy: 0.6812\n",
      "Epoch 21/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0330 - accuracy: 0.9960 - val_loss: 1.2259 - val_accuracy: 0.7246\n",
      "Epoch 22/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0175 - accuracy: 0.9992 - val_loss: 1.3712 - val_accuracy: 0.7174\n",
      "Epoch 23/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.4281 - val_accuracy: 0.7174\n",
      "Epoch 24/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.4774 - val_accuracy: 0.7174\n",
      "Epoch 25/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5209 - val_accuracy: 0.7174\n",
      "Epoch 26/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.5408 - val_accuracy: 0.7246\n",
      "Epoch 27/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.5940 - val_accuracy: 0.7101\n",
      "Epoch 28/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.6064 - val_accuracy: 0.7391\n",
      "Epoch 29/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.6448 - val_accuracy: 0.7174\n",
      "Epoch 30/30\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.6615 - val_accuracy: 0.7246\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.6615 - accuracy: 0.7246\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "history = model.fit(x_train, y_train, epochs = 30, validation_data= (x_test, y_test),callbacks=[tensorboard_callback])\n",
    "score, acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 2039, 16)          176       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 2037, 16)          784       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1018, 16)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 1018, 16)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 40)                9120      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 14,382\n",
      "Trainable params: 14,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(16, 10, activation='relu',input_shape=(2048,1)))\n",
    "model.add(layers.Conv1D(16, 3, activation='relu'))\n",
    "model.add(layers.MaxPool1D(2))\n",
    "# model.add(AveragePooling2D((5, 1), strides=(5, 1)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(40, activation=\"sigmoid\", dropout=0.25, return_sequences=False))\n",
    "model.add(layers.Dense(100,activation=\"relu\"))\n",
    "model.add(layers.Dense(2,activation=\"softmax\"))\n",
    "## rmsprop\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "# input_shape = (trial_length, nchan, 1)\n",
    "# l1 = 0\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(40, (30, 1), activation=\"relu\", kernel_regularizer=regularizers.l1(l1), padding=\"same\", input_shape=(2048,1)))\n",
    "# model.add(Conv2D(40, (1, nchan), activation=\"relu\", kernel_regularizer=regularizers.l1(l1), padding=\"valid\"))\n",
    "# model.add(AveragePooling2D((30, 1), strides=(15, 1)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(80, activation=\"relu\"))\n",
    "# model.add(Dense(2, activation=\"softmax\"))\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2/40 [>.............................] - ETA: 30s - loss: 0.7186 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.6297s vs `on_train_batch_end` time: 0.9502s). Check your callbacks.\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.6987 - accuracy: 0.4545 - val_loss: 0.6895 - val_accuracy: 0.5461\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 20s 493ms/step - loss: 0.6962 - accuracy: 0.5028 - val_loss: 0.6881 - val_accuracy: 0.5461\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 18s 438ms/step - loss: 0.6938 - accuracy: 0.5028 - val_loss: 0.6887 - val_accuracy: 0.5745\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 18s 442ms/step - loss: 0.6892 - accuracy: 0.5368 - val_loss: 0.6769 - val_accuracy: 0.5532\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 17s 435ms/step - loss: 0.6792 - accuracy: 0.5558 - val_loss: 0.6721 - val_accuracy: 0.5248\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 17s 436ms/step - loss: 0.6562 - accuracy: 0.6144 - val_loss: 0.6300 - val_accuracy: 0.6738\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 17s 435ms/step - loss: 0.6445 - accuracy: 0.6207 - val_loss: 0.6263 - val_accuracy: 0.6383\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 18s 438ms/step - loss: 0.6433 - accuracy: 0.6302 - val_loss: 0.6078 - val_accuracy: 0.6596\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 18s 439ms/step - loss: 0.6252 - accuracy: 0.6469 - val_loss: 0.6047 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 18s 441ms/step - loss: 0.6278 - accuracy: 0.6437 - val_loss: 0.6099 - val_accuracy: 0.6596\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 17s 437ms/step - loss: 0.6216 - accuracy: 0.6548 - val_loss: 0.6031 - val_accuracy: 0.6596\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 18s 441ms/step - loss: 0.6255 - accuracy: 0.6461 - val_loss: 0.6043 - val_accuracy: 0.6454\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 18s 438ms/step - loss: 0.6239 - accuracy: 0.6500 - val_loss: 0.6020 - val_accuracy: 0.6454\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 18s 444ms/step - loss: 0.6247 - accuracy: 0.6500 - val_loss: 0.6093 - val_accuracy: 0.6596\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 18s 443ms/step - loss: 0.6274 - accuracy: 0.6358 - val_loss: 0.6025 - val_accuracy: 0.6454\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 17s 436ms/step - loss: 0.6211 - accuracy: 0.6556 - val_loss: 0.6105 - val_accuracy: 0.6454\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 18s 444ms/step - loss: 0.6201 - accuracy: 0.6651 - val_loss: 0.6088 - val_accuracy: 0.6525\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 18s 440ms/step - loss: 0.6268 - accuracy: 0.6587 - val_loss: 0.6186 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 18s 438ms/step - loss: 0.6178 - accuracy: 0.6532 - val_loss: 0.6007 - val_accuracy: 0.6454\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 17s 436ms/step - loss: 0.6260 - accuracy: 0.6469 - val_loss: 0.6103 - val_accuracy: 0.6525\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.6103 - accuracy: 0.6525\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "history = model.fit(x_train, y_train, epochs = 20, validation_data= (x_test, y_test),callbacks=[tensorboard_callback])\n",
    "score, acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
