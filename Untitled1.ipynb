{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('march.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Exp_ID', 'exp_time', 'trais no.', 'note', 'signal_condition', 'gender',\n",
       "       'age', 'race', 'handiness', 'sleep condition', 'Between_sleep_RF',\n",
       "       'Q11', 'Q12', 'Q13', 'Q13_r', 'Q14', 'ID', 'ID_boy', 'ID_girl',\n",
       "       'Raw_within_RF', 'Raw_within_logistic', 'within_classification',\n",
       "       'within_classification_logistic', 'Raw_within_netVSneg_RF',\n",
       "       'Raw_within_netVSneg_logistic', 'Within_netVSneg_RF',\n",
       "       'Within_netVSneg_logistic', 'within_Feature_asymmtry_RF',\n",
       "       'within_Feature_Less_RF', 'within_Feature_Less_Logistic', 'stress',\n",
       "       'stressGroup', '42set_ID', 'race.1', 'between_classification_all',\n",
       "       'LSTM_Order_42', 'Between_Feature_asymmtry', 'Between_Feature_Less',\n",
       "       'raw_betweenNeutral2Negative', 'raw_StressGroupbetweenNeutral2Negative',\n",
       "       'raw_between_stressGroup', 'between_stressGroup',\n",
       "       'Between_Stress2groups_RF', 'Between_Stress2groups_log',\n",
       "       'Between_GenderGroup', 'Between_RandomGroup',\n",
       "       'between_stressGroup_netural_vs_negative', '39set_ID',\n",
       "       'between_classification', 'LSTM_Order_39', 'between_stressGroup.1',\n",
       "       '33set_ID', 'between_classification.1', 'between_stressGroup.2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian' 'asian' 'hispanic' 'asian' 'asian' 'aisan' 'asian' 'asian'\n",
      " 'asian' 'caucasion' 'caucasion' 'aisan' 'Black/Caucasian' 'caucasion'\n",
      " 'Black' 'Asian' 'Asian' 'Asian' 'Caucasian' 'Asian' 'Caucasian' 'Asian'\n",
      " 'Caucasian' 'Asian' 'Hipanic ' 'Asian/Caucasian' 'Asian' 'Caucasian'\n",
      " 'Asian' 'Asian' 'Asian' 'Asian' 'Asian' 'Asian' 'Asian' 'black'\n",
      " 'Caucasian' 'Asian' 'Caucasian' 'asian' nan 'asian' nan]\n",
      "['0.888888889' '0.777777778' '0.805555556' '0.666666667' '0.888888889'\n",
      " '0.861111111' '0.861111111' '0.722222222' '0.666666667' '0.722222222'\n",
      " '0.733333333' '0.5' '0.916666667' '0.766666667' '0.555555556'\n",
      " '0.694444444' '0.777777778' '0.722222222' '0.75' '0.638888889'\n",
      " '0.722222222' '0.611111111' '0.583333333' '0.75' '0.777777778'\n",
      " '0.722222222' '0.888888889' '0.666666667' '0.75' '0.638888889'\n",
      " '0.916666667' '0.805555556' '0.75' '0.694444444' '0.638888889'\n",
      " '0.861111111' '0.777777778' '0.777777778' '0.861111111' '0.766666667'\n",
      " '0.766666667' '0.733333333' '0.747089947']\n"
     ]
    }
   ],
   "source": [
    "race = df['race'].values[:-3]\n",
    "vals_rf = df['between_classification_all'].values[:-3]\n",
    "vals_lstm = df['LSTM_Order_42'].values[:-3]\n",
    "print(race)\n",
    "print(vals_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "arr2 = []\n",
    "for i in range(len(race)):\n",
    "    arr.append([race[i],vals_rf[i]])\n",
    "    arr2.append([race[i],vals_lstm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009050011628836662"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = []\n",
    "for i in range(len(arr)):\n",
    "    #if arr[i][0]=='asian':\n",
    "    one.append(float(arr[i][1]))\n",
    "# sum(one)/len(one)\n",
    "one = np.array(one)\n",
    "np.var(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.888888889',\n",
       " '0.777777778',\n",
       " '0.666666667',\n",
       " '0.888888889',\n",
       " '0.861111111',\n",
       " '0.722222222',\n",
       " '0.666666667',\n",
       " '0.766666667',\n",
       " '0.733333333']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
